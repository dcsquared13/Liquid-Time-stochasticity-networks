{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import yfinance as yf\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 16, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=yf.download(\"GOOGL\", period=\"1y\", interval=\"1d\")\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n",
    "\n",
    "#Remove unnecessary columns\n",
    "df.drop(columns=[\n",
    "    'Adj Close'],\n",
    "    inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data/time to useable format and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_norm = pd.DataFrame(x_scaled, columns = df.columns)\n",
    "\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df_norm) * 0.8)\n",
    "test_size = len(df_norm) - train_size\n",
    "train, test = df_norm.iloc[0:train_size], df_norm.iloc[train_size:len(df_norm)]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creeate train/test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 10\n",
    "\n",
    "# reshape to [samples, time_steps, n_features]\n",
    "\n",
    "X_train, y_train = create_dataset(train, train.Close, time_steps)\n",
    "X_test, y_test = create_dataset(test, test.Close, time_steps)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv1D(filters=5, kernel_size=3, activation='relu', padding='same', input_shape=(X_train.shape[0], X_train.shape[1], X_train.shape[2])))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "model.add(keras.layers.LSTM(128, stateful=True, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(32, stateful=True))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mae', optimizer=keras.optimizers.Adam(0.001), metrics=['mae', 'mape', 'acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=500\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=50,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# create reduce lr on plateau callback\n",
    "reduce_lr_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.9,\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    min_lr=0.001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=EPOCHS, \n",
    "    validation_split=0.1, \n",
    "    callbacks=[early_stopping, reduce_lr_plateau],\n",
    "    verbose=1, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(y_train)), y_train, 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test, marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
