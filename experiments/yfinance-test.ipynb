{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests-cache\n",
    "%pip install appdirs\n",
    "%pip install frozendict\n",
    "%pip install multitasking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "from lts import LTSCell\n",
    "from windowgenerator import WindowGenerator\n",
    "from baseline import Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "data=yf.download(\"GOOGL\", period=\"1y\", interval=\"1d\")\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__You can get usable signals by using sine and cosine transforms to clear \"Time of year\" signals__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df.index\n",
    "x = len(df)\n",
    "df[\"num_index\"] = range(0, x, 1)\n",
    "df.set_index(df.pop('num_index'), inplace=True)\n",
    "\n",
    "date_time = pd.to_datetime(df.pop('Date'), format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unnecessary columns\n",
    "df.drop(columns=[\n",
    "    'Adj Close'],\n",
    "    inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training, test, validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(data.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "num_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = df.index.to_numpy()\n",
    "financials = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps, financials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Window Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1, train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['Close'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Baseline\n",
    "\n",
    "baseline = Baseline(label_index=column_indices['Close'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
    "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 1 step at a time\n",
    "HORIZON = 1\n",
    "\n",
    "# use a week worth of timesteps to predict the horizon\n",
    "WINDOW_SIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(\n",
    "    input_width=WINDOW_SIZE, label_width=WINDOW_SIZE, shift=HORIZON, train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=['Close'])\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', w1.example[0].shape)\n",
    "print('Output shape:', baseline(w1.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate = .01),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with CONV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 5\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_df, \n",
    "    val_df=val_df, \n",
    "    test_df=test_df,\n",
    "    label_columns=['Close'])\n",
    "\n",
    "conv_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WIDTH = 7\n",
    "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
    "wide_conv_window = WindowGenerator(\n",
    "    input_width=INPUT_WIDTH,\n",
    "    label_width=LABEL_WIDTH,\n",
    "    shift=1,\n",
    "    train_df=train_df, \n",
    "    val_df=val_df, \n",
    "    test_df=test_df,\n",
    "    label_columns=['Close'])\n",
    "\n",
    "wide_conv_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conv model on `wide_conv_window`\")\n",
    "print('Input shape:', wide_conv_window.example[0].shape)\n",
    "print('Output shape:', wide_conv_model(conv_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(conv_model, wide_conv_window)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['Conv'] = conv_model.evaluate(wide_conv_window.val)\n",
    "performance['Conv'] = conv_model.evaluate(wide_conv_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wide window\")\n",
    "print('Input shape:', w1.example[0].shape)\n",
    "print('Labels shape:', w1.example[1].shape)\n",
    "print('Output shape:', conv_model(w1.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wide conv window\")\n",
    "print('Input shape:', wide_conv_window.example[0].shape)\n",
    "print('Labels shape:', wide_conv_window.example[1].shape)\n",
    "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_conv_window.plot(conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint with a specific filename\n",
    "def create_model_checkpoint(model_name, save_path='model_checkpoints', monitor_dataset_loss=False):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(save_path, model_name),\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        #monitor='loss' if monitor_dataset_loss else 'val_loss',\n",
    "        monitor='loss'\n",
    "    )\n",
    "\n",
    "# Create a tensorboard callback\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "    log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "    )\n",
    "\n",
    "    print(f'Saving TensorBoard log files to: {log_dir}')\n",
    "    return tensorboard_callback\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=200,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# create reduce lr on plateau callback\n",
    "reduce_lr_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    patience=100,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', w1.example[0].shape)\n",
    "print('Output shape:', lstm_model(w1.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(lstm_model, w1)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['LSTM'] = lstm_model.evaluate(w1.val)\n",
    "performance['LSTM'] = lstm_model.evaluate(w1.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.RNN(LTSCell(32), time_major=True, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(HORIZON, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(lts_nodel, w1)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "val_performance['LTS'] = lts_model.evaluate(w1.val)\n",
    "performance['LTS'] = lts_model.evaluate(w1.test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
